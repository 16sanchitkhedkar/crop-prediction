{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   temperature   humidity    rainfall label\n",
      "0    20.879744  82.002744  202.935536  rice\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('cpdata.csv')\n",
    "print(data.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data present in one row of the dataset is\n",
      "   temperature   humidity    rainfall  Black gram  Chickpea  Coconut  Coffee  \\\n",
      "0    20.879744  82.002744  202.935536           0         0        0       0   \n",
      "1    21.770462  80.319644  226.655537           0         0        0       0   \n",
      "\n",
      "   Cotton  Ground Nut  Jute  ...  maize  mango  millet  muskmelon  orange  \\\n",
      "0       0           0     0  ...      0      0       0          0       0   \n",
      "1       0           0     0  ...      0      0       0          0       0   \n",
      "\n",
      "   papaya  pomegranate  rice  watermelon  wheat  \n",
      "0       0            0     1           0      0  \n",
      "1       0            0     1           0      0  \n",
      "\n",
      "[2 rows x 33 columns]\n",
      "The Column Header : ['temperature', 'humidity', 'rainfall', 'Black gram', 'Chickpea', 'Coconut', 'Coffee', 'Cotton', 'Ground Nut', 'Jute', 'Kidney Beans', 'Lentil', 'Moth Beans', 'Mung Bean', 'Peas', 'Pigeon Peas', 'Rubber', 'Sugarcane', 'Tea', 'Tobacco', 'apple', 'banana', 'grapes', 'maize', 'mango', 'millet', 'muskmelon', 'orange', 'papaya', 'pomegranate', 'rice', 'watermelon', 'wheat']\n"
     ]
    }
   ],
   "source": [
    "#Creating dummy variable for target i.e label\n",
    "label= pd.get_dummies(data.label).iloc[: , 1:]\n",
    "data= pd.concat([data,label],axis=1)\n",
    "data.drop('label', axis=1,inplace=True)\n",
    "print('The data present in one row of the dataset is')\n",
    "print(data.head(2))\n",
    "column_headers = list(data.columns.values)\n",
    "print(\"The Column Header :\", column_headers)\n",
    "train=data.iloc[:, 0:3].values\n",
    "test=data.iloc[: ,3:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2790, 3)\n",
      "[30.10773379 90.34546355 75.24521981]\n",
      "(2790, 30)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#Dividing the data into training and test set\n",
    "X_train,X_test,y_train,y_test=train_test_split(train,test,test_size=0.1)\n",
    "print(X_train.shape)\n",
    "print(X_test[0])\n",
    "print(y_train.shape)\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_var():\n",
    "    w1 = np.random.rand(30, 3) - 0.5\n",
    "    b1 = np.random.rand(30, 1) - 0.5\n",
    "    w2 = np.random.rand(30, 30) - 0.5\n",
    "    b2 = np.random.rand(30, 1) - 0.5\n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(z):\n",
    "    return np.maximum(z, 0)\n",
    "\n",
    "def Softmax(Z):\n",
    "    A = np.exp(Z) / sum(np.exp(Z))\n",
    "    return A\n",
    "\n",
    "def derv_ReLU(z):\n",
    "    return z > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arr is a 2d numpy array, assign the maximum value in each row to 1 and the rest to 0\n",
    "def max_to_one(arr, m, n):\n",
    "    for i in range(0, m):\n",
    "        d = np.argmax(arr[i])\n",
    "        for j in range(0, n):\n",
    "            if(d == j):\n",
    "                arr[i][j] = 1\n",
    "            else:\n",
    "                arr[i][j] = 0\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(w1, b1, w2, b2, x):\n",
    "    z1 = w1.dot(x) + b1\n",
    "    a1 = ReLU(z1)\n",
    "    z2 = w2.dot(a1) + b2\n",
    "    a2 = Softmax(z2)\n",
    "    a2 = a2.T\n",
    "    #find the number of rows in a2\n",
    "    m = a2.shape[0]\n",
    "    a2 = max_to_one(a2, m, 30)\n",
    "    # print(a2)\n",
    "    # print(a2.shape)\n",
    "    return z1, a1, z2, a2\n",
    "\n",
    "def back_prop(w1, b1, w2, b2, x, y, z1, a1, z2, a2):\n",
    "    m = y.size\n",
    "    dz2 = (a2 - y).T\n",
    "    dw2 = 1 / m * (dz2.dot(a1.T))\n",
    "    db2 = 1 / m * np.sum(dz2)\n",
    "    dz1 = w2.T.dot(dz2) * derv_ReLU(z1)\n",
    "    dw1 = 1 / m * (dz1.dot(x.T))\n",
    "    db1 = 1 / m * np.sum(dz1)\n",
    "    return dw1, db1, dw2, db2\n",
    "\n",
    "def update_var(w1, b1, w2, b2, dw1, db1, dw2, db2, learning_rate):\n",
    "    w1 = w1 - learning_rate * dw1\n",
    "    b1 = b1 - learning_rate * db1\n",
    "    w2 = w2 - learning_rate * dw2\n",
    "    b2 = b2 - learning_rate * db2\n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y):\n",
    "    return np.mean(y_pred == y)\n",
    "\n",
    "def grad_descent(x, y, alpha, w1, b1, w2, b2):\n",
    "    z1, a1, z2, a2 = forward_prop(w1, b1, w2, b2, x)\n",
    "    dw1, db1, dw2, db2 = back_prop(w1, b1, w2, b2, x, y, z1, a1, z2, a2)\n",
    "    w1, b1, w2, b2 = update_var(w1, b1, w2, b2, dw1, db1, dw2, db2, alpha)\n",
    "    return w1, b1, w2, b2, a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "Accuracy:  0.9382902298850574\n",
      "Iteration:  1\n",
      "Accuracy:  0.9391642720306513\n",
      "Iteration:  2\n",
      "Accuracy:  0.9395035121328225\n",
      "Iteration:  3\n",
      "Accuracy:  0.9397090517241378\n",
      "Iteration:  4\n",
      "Accuracy:  0.939875478927203\n",
      "Iteration:  5\n",
      "Accuracy:  0.9399664750957855\n",
      "Iteration:  6\n",
      "Accuracy:  0.9400348932676518\n",
      "Iteration:  7\n",
      "Accuracy:  0.9400951867816093\n",
      "Iteration:  8\n",
      "Accuracy:  0.9401367603235419\n",
      "Iteration:  9\n",
      "Accuracy:  0.9401592432950191\n",
      "Iteration:  10\n",
      "Accuracy:  0.9401830808080809\n",
      "Iteration:  11\n",
      "Accuracy:  0.9402229007024265\n",
      "Iteration:  12\n",
      "Accuracy:  0.94024738432066\n",
      "Iteration:  13\n",
      "Accuracy:  0.9402717911877393\n",
      "Iteration:  14\n",
      "Accuracy:  0.9402961366538952\n",
      "Iteration:  15\n",
      "Accuracy:  0.9403174389367817\n",
      "Iteration:  16\n",
      "Accuracy:  0.9403348264593193\n",
      "Iteration:  17\n",
      "Accuracy:  0.9403496168582376\n",
      "Iteration:  18\n",
      "Accuracy:  0.9403596995361967\n",
      "Iteration:  19\n",
      "Accuracy:  0.9403735632183908\n",
      "Iteration:  20\n",
      "Accuracy:  0.9403855363984673\n",
      "Iteration:  21\n",
      "Accuracy:  0.9403991422849182\n",
      "Iteration:  22\n",
      "Accuracy:  0.940405838747293\n",
      "Iteration:  23\n",
      "Accuracy:  0.9404174648786718\n",
      "Iteration:  24\n",
      "Accuracy:  0.9404252873563218\n",
      "Iteration:  25\n",
      "Accuracy:  0.9404334291187739\n",
      "Iteration:  26\n",
      "Accuracy:  0.9404427415921668\n",
      "Iteration:  27\n",
      "Accuracy:  0.9404479679802954\n",
      "Iteration:  28\n",
      "Accuracy:  0.9404536596644206\n",
      "Iteration:  29\n",
      "Accuracy:  0.9404605683269476\n",
      "Iteration:  30\n",
      "Accuracy:  0.9404678037325424\n",
      "Iteration:  31\n",
      "Accuracy:  0.9404738386015326\n",
      "Iteration:  32\n",
      "Accuracy:  0.9404776936026937\n",
      "Iteration:  33\n",
      "Accuracy:  0.9404823782961461\n",
      "Iteration:  34\n",
      "Accuracy:  0.9404861111111112\n",
      "Iteration:  35\n",
      "Accuracy:  0.9404889713707962\n",
      "Iteration:  36\n",
      "Accuracy:  0.9404903826240034\n",
      "Iteration:  37\n",
      "Accuracy:  0.9404955006049607\n",
      "Iteration:  38\n",
      "Accuracy:  0.9404997421161215\n",
      "Iteration:  39\n",
      "Accuracy:  0.9405055675287356\n",
      "Iteration:  40\n",
      "Accuracy:  0.9405081884870573\n",
      "Iteration:  41\n",
      "Accuracy:  0.9405112547892721\n",
      "Iteration:  42\n",
      "Accuracy:  0.9405141784727792\n",
      "Iteration:  43\n",
      "Accuracy:  0.9405175134970395\n",
      "Iteration:  44\n",
      "Accuracy:  0.9405212324393359\n",
      "Iteration:  45\n",
      "Accuracy:  0.9405242691154423\n",
      "Iteration:  46\n",
      "Accuracy:  0.9405276860683134\n",
      "Iteration:  47\n",
      "Accuracy:  0.9405309606481481\n",
      "Iteration:  48\n",
      "Accuracy:  0.9405345902728908\n",
      "Iteration:  49\n",
      "Accuracy:  0.9405371168582375\n",
      "Iteration:  50\n",
      "Accuracy:  0.9405388400570956\n",
      "Iteration:  51\n",
      "Accuracy:  0.9405400364721483\n",
      "Iteration:  52\n",
      "Accuracy:  0.940543220920986\n",
      "Iteration:  53\n",
      "Accuracy:  0.9405449570739322\n",
      "Iteration:  54\n",
      "Accuracy:  0.9405470654824102\n",
      "Iteration:  55\n",
      "Accuracy:  0.9405493123973727\n",
      "Iteration:  56\n",
      "Accuracy:  0.940552110640586\n",
      "Iteration:  57\n",
      "Accuracy:  0.9405543995243758\n",
      "Iteration:  58\n",
      "Accuracy:  0.9405562049483732\n",
      "Iteration:  59\n",
      "Accuracy:  0.9405587484035761\n",
      "Iteration:  60\n",
      "Accuracy:  0.9405600307769614\n",
      "Iteration:  61\n",
      "Accuracy:  0.9405624304783091\n",
      "Iteration:  62\n",
      "Accuracy:  0.9405645639481847\n",
      "Iteration:  63\n",
      "Accuracy:  0.9405668178280652\n",
      "Iteration:  64\n",
      "Accuracy:  0.9405682655467138\n",
      "Iteration:  65\n",
      "Accuracy:  0.9405696693951006\n",
      "Iteration:  66\n",
      "Accuracy:  0.9405708526333847\n",
      "Iteration:  67\n",
      "Accuracy:  0.9405728814514311\n",
      "Iteration:  68\n",
      "Accuracy:  0.9405739838414127\n",
      "Iteration:  69\n",
      "Accuracy:  0.9405757389162562\n",
      "Iteration:  70\n",
      "Accuracy:  0.9405776131887107\n",
      "Iteration:  71\n",
      "Accuracy:  0.9405797679863771\n",
      "Iteration:  72\n",
      "Accuracy:  0.9405815357161602\n",
      "Iteration:  73\n",
      "Accuracy:  0.9405832556694627\n",
      "Iteration:  74\n",
      "Accuracy:  0.9405852490421457\n",
      "Iteration:  75\n",
      "Accuracy:  0.9405868748739665\n",
      "Iteration:  76\n",
      "Accuracy:  0.9405884584763894\n",
      "Iteration:  77\n",
      "Accuracy:  0.9405896944690049\n",
      "Iteration:  78\n",
      "Accuracy:  0.9405908991706677\n",
      "Iteration:  79\n",
      "Accuracy:  0.9405926724137931\n",
      "Iteration:  80\n",
      "Accuracy:  0.9405941062390616\n",
      "Iteration:  81\n",
      "Accuracy:  0.9405955050929821\n",
      "Iteration:  82\n",
      "Accuracy:  0.940596870239579\n",
      "Iteration:  83\n",
      "Accuracy:  0.9405982028826856\n",
      "Iteration:  84\n",
      "Accuracy:  0.9405995041694839\n",
      "Iteration:  85\n",
      "Accuracy:  0.9406006359707743\n",
      "Iteration:  86\n",
      "Accuracy:  0.9406018793764037\n",
      "Iteration:  87\n",
      "Accuracy:  0.9406033666405434\n",
      "Iteration:  88\n",
      "Accuracy:  0.9406046859529037\n",
      "Iteration:  89\n",
      "Accuracy:  0.9406061089825457\n",
      "Iteration:  90\n",
      "Accuracy:  0.9406075007368111\n",
      "Iteration:  91\n",
      "Accuracy:  0.9406088622355488\n",
      "Iteration:  92\n",
      "Accuracy:  0.9406099369670005\n",
      "Iteration:  93\n",
      "Accuracy:  0.9406109888318254\n",
      "Iteration:  94\n",
      "Accuracy:  0.9406120185521276\n",
      "Iteration:  95\n",
      "Accuracy:  0.9406132762611751\n",
      "Iteration:  96\n",
      "Accuracy:  0.940614261168385\n",
      "Iteration:  97\n",
      "Accuracy:  0.9406154703260615\n",
      "Iteration:  98\n",
      "Accuracy:  0.9406164131738846\n",
      "Iteration:  99\n",
      "Accuracy:  0.9406175766283527\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "batch_size = 32\n",
    "n_example = 2790\n",
    "batches = int(n_example/batch_size)\n",
    "epochs = 100\n",
    "w1, b1, w2, b2 = init_var()\n",
    "acc = np.empty(0)\n",
    "for epoch in range(epochs):\n",
    "    i = shuffle(range(n_example))\n",
    "    for b in range(batches):\n",
    "        x_batch = X_train[i[b*batch_size:(b+1)*batch_size]]\n",
    "        y_batch = y_train[i[b*batch_size:(b+1)*batch_size]]\n",
    "        w1, b1, w2, b2, a2 = grad_descent(x_batch.T, y_batch, 0.1, w1, b1, w2, b2)\n",
    "        acc = np.append(acc, accuracy(a2, y_batch))\n",
    "    print(\"Iteration: \", epoch)\n",
    "    print(\"Accuracy: \", np.mean(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45.3 27.7 71.2]]\n",
      "(1, 3)\n"
     ]
    }
   ],
   "source": [
    "atemp, ah, rain = 45.3, 27.7, 71.2\n",
    "l=[]\n",
    "l.append(atemp)\n",
    "l.append(ah)\n",
    "l.append(rain)\n",
    "#create a numpy arrray with atemp, ah and rain\n",
    "predictcrop = np.array(l)\n",
    "predictcrop = predictcrop.reshape(1, 3)\n",
    "print(predictcrop)\n",
    "print(predictcrop.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "# Putting the names of crop in a single list\n",
    "crops=['Black gram', 'Chickpea', 'Coconut', 'Coffee', 'Cotton', 'Ground Nut', 'Jute', 'Kidney Beans', 'Lentil', 'Moth Beans', 'Mung Bean', 'Peas', 'Pigeon Peas', 'Rubber', 'Sugarcane', 'Tea', 'Tobacco', 'apple', 'banana', 'grapes', 'maize', 'mango', 'millet', 'muskmelon', 'orange', 'papaya', 'pomegranate', 'rice', 'watermelon', 'wheat']\n",
    "print(len(crops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(w1, b1, w2, b2, x):\n",
    "    z1 = w1.dot(x) + b1\n",
    "    a1 = ReLU(z1)\n",
    "    z2 = w2.dot(a1) + b2\n",
    "    a2 = Softmax(z2)\n",
    "    a2 = a2.T\n",
    "    #a2 = max_to_one(a2, 30, 30)\n",
    "    return a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45.3 27.7 71.2]]\n",
      "[[0.06139362 0.02264354 0.00481489 0.00942125 0.00696515 0.07506778\n",
      "  0.00912583 0.02536149 0.01633189 0.06128055 0.08035828 0.07338618\n",
      "  0.05735041 0.02037374 0.02427284 0.02958897 0.0351934  0.02803672\n",
      "  0.02734176 0.03334661 0.00942459 0.0158971  0.04270099 0.01692395\n",
      "  0.03578801 0.00909738 0.05692328 0.06074951 0.02302301 0.02781725]]\n",
      "Recommended crops are: \n",
      "Ground Nut\n",
      "Mung Bean\n",
      "Peas\n"
     ]
    }
   ],
   "source": [
    "# print(w1.shape)\n",
    "# print(b1.shape)\n",
    "# print(w2.shape)\n",
    "# print(b2.shape)\n",
    "# print(predictcrop.shape)\n",
    "# x1 = w1\n",
    "# x2 = b1\n",
    "# x3 = w2\n",
    "# x4 = b2\n",
    "print(predictcrop)\n",
    "a2 = pred(w1, b1, w2, b2, predictcrop.T)\n",
    "#print(a2.shape)\n",
    "#print(a2)\n",
    "#find mean of each column of a2\n",
    "#a2 = np.mean(a2, axis=0)\n",
    "#find maximum in a2\n",
    "# d = np.argmax(a2[0])\n",
    "# #find the index of the second largest number in a2\n",
    "# d2 = np.argpartition(a2.flatten(), -2)[-2]\n",
    "# print(\"The crop recommended is \",crops[d])\n",
    "# print(d)\n",
    "# print(\"The second crop recommended is \",crops[d2])\n",
    "# print(d2)\n",
    "# print(a2)\n",
    "thres = 0.07\n",
    "df = np.argwhere(a2 > thres)\n",
    "# print(df)\n",
    "print(\"Recommended crops are: \")\n",
    "if not df.size:\n",
    "    print(\"Null\")\n",
    "for i in df:\n",
    "    print(crops[i[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
