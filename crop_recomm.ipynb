{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   temperature   humidity    rainfall label\n",
      "0    20.879744  82.002744  202.935536  rice\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('cpdata.csv')\n",
    "print(data.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data present in one row of the dataset is\n",
      "   temperature   humidity    rainfall  Black gram  Chickpea  Coconut  Coffee  \\\n",
      "0    20.879744  82.002744  202.935536           0         0        0       0   \n",
      "1    21.770462  80.319644  226.655537           0         0        0       0   \n",
      "\n",
      "   Cotton  Ground Nut  Jute  ...  maize  mango  millet  muskmelon  orange  \\\n",
      "0       0           0     0  ...      0      0       0          0       0   \n",
      "1       0           0     0  ...      0      0       0          0       0   \n",
      "\n",
      "   papaya  pomegranate  rice  watermelon  wheat  \n",
      "0       0            0     1           0      0  \n",
      "1       0            0     1           0      0  \n",
      "\n",
      "[2 rows x 33 columns]\n",
      "The Column Header : ['temperature', 'humidity', 'rainfall', 'Black gram', 'Chickpea', 'Coconut', 'Coffee', 'Cotton', 'Ground Nut', 'Jute', 'Kidney Beans', 'Lentil', 'Moth Beans', 'Mung Bean', 'Peas', 'Pigeon Peas', 'Rubber', 'Sugarcane', 'Tea', 'Tobacco', 'apple', 'banana', 'grapes', 'maize', 'mango', 'millet', 'muskmelon', 'orange', 'papaya', 'pomegranate', 'rice', 'watermelon', 'wheat']\n"
     ]
    }
   ],
   "source": [
    "#Creating dummy variable for target i.e label\n",
    "label= pd.get_dummies(data.label).iloc[: , 1:]\n",
    "data= pd.concat([data,label],axis=1)\n",
    "data.drop('label', axis=1,inplace=True)\n",
    "print('The data present in one row of the dataset is')\n",
    "print(data.head(2))\n",
    "column_headers = list(data.columns.values)\n",
    "print(\"The Column Header :\", column_headers)\n",
    "train=data.iloc[:, 0:3].values\n",
    "test=data.iloc[: ,3:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2790, 3)\n",
      "[19.0781471  69.02298571 80.72515943]\n",
      "(2790, 30)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#Dividing the data into training and test set\n",
    "X_train,X_test,y_train,y_test=train_test_split(train,test,test_size=0.1)\n",
    "print(X_train.shape)\n",
    "print(X_test[0])\n",
    "print(y_train.shape)\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_var():\n",
    "    w1 = np.random.rand(30, 3) - 0.5\n",
    "    b1 = np.random.rand(30, 1) - 0.5\n",
    "    w2 = np.random.rand(30, 30) - 0.5\n",
    "    b2 = np.random.rand(30, 1) - 0.5\n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(z):\n",
    "    return np.maximum(z, 0)\n",
    "\n",
    "def Softmax(Z):\n",
    "    A = np.exp(Z) / sum(np.exp(Z))\n",
    "    return A\n",
    "\n",
    "def derv_ReLU(z):\n",
    "    return z > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arr is a 2d numpy array, assign the maximum value in each row to 1 and the rest to 0\n",
    "def max_to_one(arr, m, n):\n",
    "    for i in range(0, m):\n",
    "        d = np.argmax(arr[i])\n",
    "        for j in range(0, n):\n",
    "            if(d == j):\n",
    "                arr[i][j] = 1\n",
    "            else:\n",
    "                arr[i][j] = 0\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(w1, b1, w2, b2, x):\n",
    "    z1 = w1.dot(x) + b1\n",
    "    a1 = ReLU(z1)\n",
    "    z2 = w2.dot(a1) + b2\n",
    "    a2 = Softmax(z2)\n",
    "    a2 = a2.T\n",
    "    #find the number of rows in a2\n",
    "    m = a2.shape[0]\n",
    "    a2 = max_to_one(a2, m, 30)\n",
    "    # print(a2)\n",
    "    # print(a2.shape)\n",
    "    return z1, a1, z2, a2\n",
    "\n",
    "def back_prop(w1, b1, w2, b2, x, y, z1, a1, z2, a2):\n",
    "    m = y.size\n",
    "    dz2 = (a2 - y).T\n",
    "    dw2 = 1 / m * (dz2.dot(a1.T))\n",
    "    db2 = 1 / m * np.sum(dz2)\n",
    "    dz1 = w2.T.dot(dz2) * derv_ReLU(z1)\n",
    "    dw1 = 1 / m * (dz1.dot(x.T))\n",
    "    db1 = 1 / m * np.sum(dz1)\n",
    "    return dw1, db1, dw2, db2\n",
    "\n",
    "def update_var(w1, b1, w2, b2, dw1, db1, dw2, db2, learning_rate):\n",
    "    w1 = w1 - learning_rate * dw1\n",
    "    b1 = b1 - learning_rate * db1\n",
    "    w2 = w2 - learning_rate * dw2\n",
    "    b2 = b2 - learning_rate * db2\n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y):\n",
    "    return np.mean(y_pred == y)\n",
    "\n",
    "def grad_descent(x, y, alpha, w1, b1, w2, b2):\n",
    "    z1, a1, z2, a2 = forward_prop(w1, b1, w2, b2, x)\n",
    "    dw1, db1, dw2, db2 = back_prop(w1, b1, w2, b2, x, y, z1, a1, z2, a2)\n",
    "    w1, b1, w2, b2 = update_var(w1, b1, w2, b2, dw1, db1, dw2, db2, alpha)\n",
    "    return w1, b1, w2, b2, a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "Accuracy:  0.9377993295019156\n",
      "Iteration:  1\n",
      "Accuracy:  0.9384339080459769\n",
      "Iteration:  2\n",
      "Accuracy:  0.938661398467433\n",
      "Iteration:  3\n",
      "Accuracy:  0.9387811302681992\n",
      "Iteration:  4\n",
      "Accuracy:  0.9388433908045978\n",
      "Iteration:  5\n",
      "Accuracy:  0.9388908844189017\n",
      "Iteration:  6\n",
      "Accuracy:  0.9389265188834154\n",
      "Iteration:  7\n",
      "Accuracy:  0.9389442648467432\n",
      "Iteration:  8\n",
      "Accuracy:  0.9389660493827162\n",
      "Iteration:  9\n",
      "Accuracy:  0.9389834770114943\n",
      "Iteration:  10\n",
      "Accuracy:  0.9390042668059909\n",
      "Iteration:  11\n",
      "Accuracy:  0.9390176005747126\n",
      "Iteration:  12\n",
      "Accuracy:  0.9390270409666962\n",
      "Iteration:  13\n",
      "Accuracy:  0.9390368431855501\n",
      "Iteration:  14\n",
      "Accuracy:  0.9390437420178798\n",
      "Iteration:  15\n",
      "Accuracy:  0.9390497784961686\n",
      "Iteration:  16\n",
      "Accuracy:  0.9390544004958304\n",
      "Iteration:  17\n",
      "Accuracy:  0.939053852703278\n",
      "Iteration:  18\n",
      "Accuracy:  0.939059664246824\n",
      "Iteration:  19\n",
      "Accuracy:  0.9390636973180077\n",
      "Iteration:  20\n",
      "Accuracy:  0.9390662059843095\n",
      "Iteration:  21\n",
      "Accuracy:  0.9390717520027865\n",
      "Iteration:  22\n",
      "Accuracy:  0.9390736923205064\n",
      "Iteration:  23\n",
      "Accuracy:  0.9390774664750958\n",
      "Iteration:  24\n",
      "Accuracy:  0.9390790229885057\n",
      "Iteration:  25\n",
      "Accuracy:  0.9390823017978192\n",
      "Iteration:  26\n",
      "Accuracy:  0.939080459770115\n",
      "Iteration:  27\n",
      "Accuracy:  0.9390838806787084\n",
      "Iteration:  28\n",
      "Accuracy:  0.9390841755846214\n",
      "Iteration:  29\n",
      "Accuracy:  0.9390868454661557\n",
      "Iteration:  30\n",
      "Accuracy:  0.9390893430972684\n",
      "Iteration:  31\n",
      "Accuracy:  0.9390901879789271\n",
      "Iteration:  32\n",
      "Accuracy:  0.9390924329501914\n",
      "Iteration:  33\n",
      "Accuracy:  0.939094545864323\n",
      "Iteration:  34\n",
      "Accuracy:  0.9390979064039409\n",
      "Iteration:  35\n",
      "Accuracy:  0.9391010802469135\n",
      "Iteration:  36\n",
      "Accuracy:  0.9391027881329606\n",
      "Iteration:  37\n",
      "Accuracy:  0.939105351381327\n",
      "Iteration:  38\n",
      "Accuracy:  0.9391065551625897\n",
      "Iteration:  39\n",
      "Accuracy:  0.9391073994252873\n",
      "Iteration:  40\n",
      "Accuracy:  0.9391087865620037\n",
      "Iteration:  41\n",
      "Accuracy:  0.9391101076445904\n",
      "Iteration:  42\n",
      "Accuracy:  0.9391110888354273\n",
      "Iteration:  43\n",
      "Accuracy:  0.9391128417798676\n",
      "Iteration:  44\n",
      "Accuracy:  0.9391134525329927\n",
      "Iteration:  45\n",
      "Accuracy:  0.939114557304681\n",
      "Iteration:  46\n",
      "Accuracy:  0.939115615064808\n",
      "Iteration:  47\n",
      "Accuracy:  0.9391166287515964\n",
      "Iteration:  48\n",
      "Accuracy:  0.9391190671670967\n",
      "Iteration:  49\n",
      "Accuracy:  0.9391199712643679\n",
      "Iteration:  50\n",
      "Accuracy:  0.9391217789797911\n",
      "Iteration:  51\n",
      "Accuracy:  0.9391239776746243\n",
      "Iteration:  52\n",
      "Accuracy:  0.9391260933998411\n",
      "Iteration:  53\n",
      "Accuracy:  0.9391263569604087\n",
      "Iteration:  54\n",
      "Accuracy:  0.9391274817136886\n",
      "Iteration:  55\n",
      "Accuracy:  0.9391285662972085\n",
      "Iteration:  56\n",
      "Accuracy:  0.9391300329367481\n",
      "Iteration:  57\n",
      "Accuracy:  0.9391314490025103\n",
      "Iteration:  58\n",
      "Accuracy:  0.9391324111955321\n",
      "Iteration:  59\n",
      "Accuracy:  0.9391333413154535\n",
      "Iteration:  60\n",
      "Accuracy:  0.9391334558130771\n",
      "Iteration:  61\n",
      "Accuracy:  0.9391333735014215\n",
      "Iteration:  62\n",
      "Accuracy:  0.9391315833485373\n",
      "Iteration:  63\n",
      "Accuracy:  0.9391291008141762\n",
      "Iteration:  64\n",
      "Accuracy:  0.939128168287651\n",
      "Iteration:  65\n",
      "Accuracy:  0.9391247242540347\n",
      "Iteration:  66\n",
      "Accuracy:  0.9391210256190313\n",
      "Iteration:  67\n",
      "Accuracy:  0.939133810851927\n",
      "Iteration:  68\n",
      "Accuracy:  0.9391526458992726\n",
      "Iteration:  69\n",
      "Accuracy:  0.9391736795292829\n",
      "Iteration:  70\n",
      "Accuracy:  0.9391931088446388\n",
      "Iteration:  71\n",
      "Accuracy:  0.9392133288101321\n",
      "Iteration:  72\n",
      "Accuracy:  0.939231190626148\n",
      "Iteration:  73\n",
      "Accuracy:  0.9392516438852646\n",
      "Iteration:  74\n",
      "Accuracy:  0.9392709131545338\n",
      "Iteration:  75\n",
      "Accuracy:  0.9392887300867111\n",
      "Iteration:  76\n",
      "Accuracy:  0.9393079501915708\n",
      "Iteration:  77\n",
      "Accuracy:  0.9393272914824639\n",
      "Iteration:  78\n",
      "Accuracy:  0.93934584000194\n",
      "Iteration:  79\n",
      "Accuracy:  0.9393627274904215\n",
      "Iteration:  80\n",
      "Accuracy:  0.9393797892720308\n",
      "Iteration:  81\n",
      "Accuracy:  0.939399647229231\n",
      "Iteration:  82\n",
      "Accuracy:  0.9394161415778055\n",
      "Iteration:  83\n",
      "Accuracy:  0.9394308178252143\n",
      "Iteration:  84\n",
      "Accuracy:  0.9394459939148073\n",
      "Iteration:  85\n",
      "Accuracy:  0.9394591463957943\n",
      "Iteration:  86\n",
      "Accuracy:  0.9394736479940107\n",
      "Iteration:  87\n",
      "Accuracy:  0.9394864594218043\n",
      "Iteration:  88\n",
      "Accuracy:  0.9394983103017781\n",
      "Iteration:  89\n",
      "Accuracy:  0.9395124255002129\n",
      "Iteration:  90\n",
      "Accuracy:  0.9395243884468022\n",
      "Iteration:  91\n",
      "Accuracy:  0.9395350501832417\n",
      "Iteration:  92\n",
      "Accuracy:  0.9395483150002061\n",
      "Iteration:  93\n",
      "Accuracy:  0.9395574763593382\n",
      "Iteration:  94\n",
      "Accuracy:  0.9395627898769914\n",
      "Iteration:  95\n",
      "Accuracy:  0.9395657477250958\n",
      "Iteration:  96\n",
      "Accuracy:  0.9395628431488724\n",
      "Iteration:  97\n",
      "Accuracy:  0.939558287395418\n",
      "Iteration:  98\n",
      "Accuracy:  0.9395569681489222\n",
      "Iteration:  99\n",
      "Accuracy:  0.9395511254789272\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "batch_size = 32\n",
    "n_example = 2790\n",
    "batches = int(n_example/batch_size)\n",
    "epochs = 100\n",
    "w1, b1, w2, b2 = init_var()\n",
    "acc = np.empty(0)\n",
    "for epoch in range(epochs):\n",
    "    i = shuffle(range(n_example))\n",
    "    for b in range(batches):\n",
    "        x_batch = X_train[i[b*batch_size:(b+1)*batch_size]]\n",
    "        y_batch = y_train[i[b*batch_size:(b+1)*batch_size]]\n",
    "        w1, b1, w2, b2, a2 = grad_descent(x_batch.T, y_batch, 0.1, w1, b1, w2, b2)\n",
    "        acc = np.append(acc, accuracy(a2, y_batch))\n",
    "    print(\"Iteration: \", epoch)\n",
    "    print(\"Accuracy: \", np.mean(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 27.98  84.58 136.72]]\n",
      "(1, 3)\n"
     ]
    }
   ],
   "source": [
    "atemp, ah, rain = 27.98, 84.58, 136.72\n",
    "l=[]\n",
    "l.append(atemp)\n",
    "l.append(ah)\n",
    "l.append(rain)\n",
    "#create a numpy arrray with atemp, ah and rain\n",
    "predictcrop = np.array(l)\n",
    "predictcrop = predictcrop.reshape(1, 3)\n",
    "print(predictcrop)\n",
    "print(predictcrop.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "# Putting the names of crop in a single list\n",
    "crops=['Black gram', 'Chickpea', 'Coconut', 'Coffee', 'Cotton', 'Ground Nut', 'Jute', 'Kidney Beans', 'Lentil', 'Moth Beans', 'Mung Bean', 'Peas', 'Pigeon Peas', 'Rubber', 'Sugarcane', 'Tea', 'Tobacco', 'apple', 'banana', 'grapes', 'maize', 'mango', 'millet', 'muskmelon', 'orange', 'papaya', 'pomegranate', 'rice', 'watermelon', 'wheat']\n",
    "print(len(crops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(w1, b1, w2, b2, x):\n",
    "    z1 = w1.dot(x) + b1\n",
    "    a1 = ReLU(z1)\n",
    "    z2 = w2.dot(a1) + b2\n",
    "    a2 = Softmax(z2)\n",
    "    a2 = a2.T\n",
    "    #a2 = max_to_one(a2, 30, 30)\n",
    "    return a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 27.98  84.58 136.72]]\n",
      "(1, 30)\n",
      "[[0.03116448 0.03573726 0.04494595 0.041833   0.04912877 0.04363539\n",
      "  0.03159376 0.0325121  0.05255235 0.02366188 0.05441477 0.03077614\n",
      "  0.0223424  0.02114634 0.03213497 0.03711945 0.04737735 0.02358905\n",
      "  0.04128414 0.0358893  0.02319309 0.0302635  0.02477444 0.02084793\n",
      "  0.04309872 0.02692784 0.02110092 0.02244417 0.02993451 0.02457603]]\n",
      "The crop recommended is  Mung Bean\n",
      "10\n",
      "The second crop recommended is  Lentil\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# print(w1.shape)\n",
    "# print(b1.shape)\n",
    "# print(w2.shape)\n",
    "# print(b2.shape)\n",
    "# print(predictcrop.shape)\n",
    "# x1 = w1\n",
    "# x2 = b1\n",
    "# x3 = w2\n",
    "# x4 = b2\n",
    "print(predictcrop)\n",
    "a2 = pred(w1, b1, w2, b2, predictcrop.T)\n",
    "print(a2.shape)\n",
    "print(a2)\n",
    "#find mean of each column of a2\n",
    "#a2 = np.mean(a2, axis=0)\n",
    "#find maximum in a2\n",
    "d = np.argmax(a2[0])\n",
    "#find the index of the second largest number in a2\n",
    "d2 = np.argpartition(a2.flatten(), -2)[-2]\n",
    "print(\"The crop recommended is \",crops[d])\n",
    "print(d)\n",
    "print(\"The second crop recommended is \",crops[d2])\n",
    "print(d2)\n",
    "#print(a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
